{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1548, 19)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data gathering\n",
    "df_label = pd.read_csv('Credit_card_label.csv')\n",
    "df_features = pd.read_csv('Credit_card.csv')\n",
    "df = pd.merge(df_label, df_features, on='Ind_ID')\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "### Drop row with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "Ind_ID               0\n",
      "label                0\n",
      "GENDER               7\n",
      "Car_Owner            0\n",
      "Propert_Owner        0\n",
      "CHILDREN             0\n",
      "Annual_income       23\n",
      "Type_Income          0\n",
      "EDUCATION            0\n",
      "Marital_status       0\n",
      "Housing_type         0\n",
      "Birthday_count      22\n",
      "Employed_days        0\n",
      "Mobile_phone         0\n",
      "Work_Phone           0\n",
      "Phone                0\n",
      "EMAIL_ID             0\n",
      "Type_Occupation    488\n",
      "Family_Members       0\n",
      "dtype: int64\n",
      "\n",
      "After\n",
      "Ind_ID             0\n",
      "label              0\n",
      "GENDER             0\n",
      "Car_Owner          0\n",
      "Propert_Owner      0\n",
      "CHILDREN           0\n",
      "Annual_income      0\n",
      "Type_Income        0\n",
      "EDUCATION          0\n",
      "Marital_status     0\n",
      "Housing_type       0\n",
      "Birthday_count     0\n",
      "Employed_days      0\n",
      "Mobile_phone       0\n",
      "Work_Phone         0\n",
      "Phone              0\n",
      "EMAIL_ID           0\n",
      "Type_Occupation    0\n",
      "Family_Members     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Before')\n",
    "print(df.isnull().sum())\n",
    "df = df.dropna()\n",
    "print('\\nAfter')\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unrelated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'GENDER', 'Car_Owner', 'Propert_Owner', 'CHILDREN',\n",
       "       'Annual_income', 'Type_Income', 'EDUCATION', 'Marital_status',\n",
       "       'Housing_type', 'Birthday_count', 'Employed_days', 'Type_Occupation',\n",
       "       'Family_Members'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Ind_ID', 'Mobile_phone', 'Work_Phone', 'Phone', 'EMAIL_ID'], axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop duplicated feature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates before : 112\n",
      "Duplicates after : 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(913, 14)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Duplicates before : {df.duplicated().sum()}')\n",
    "df = df.drop_duplicates().reset_index().drop('index', axis=1)\n",
    "print(f'Duplicates after : {df.duplicated().sum()}')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Encode non-numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Car_Owner',\n",
       " 'Type_Income',\n",
       " 'Housing_type',\n",
       " 'Propert_Owner',\n",
       " 'EDUCATION',\n",
       " 'Type_Occupation',\n",
       " 'Marital_status',\n",
       " 'GENDER']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_numeric_col = list((set(df.columns)-set(df.describe().columns)))\n",
    "non_numeric_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N': 0, 'Y': 1}\n",
      "{'Commercial associate': 0, 'Pensioner': 1, 'State servant': 2, 'Working': 3}\n",
      "{'Co-op apartment': 0, 'House / apartment': 1, 'Municipal apartment': 2, 'Office apartment': 3, 'Rented apartment': 4, 'With parents': 5}\n",
      "{'N': 0, 'Y': 1}\n",
      "{'Higher education': 0, 'Incomplete higher': 1, 'Lower secondary': 2, 'Secondary / secondary special': 3}\n",
      "{'Accountants': 0, 'Cleaning staff': 1, 'Cooking staff': 2, 'Core staff': 3, 'Drivers': 4, 'HR staff': 5, 'High skill tech staff': 6, 'IT staff': 7, 'Laborers': 8, 'Low-skill Laborers': 9, 'Managers': 10, 'Medicine staff': 11, 'Private service staff': 12, 'Realty agents': 13, 'Sales staff': 14, 'Secretaries': 15, 'Security staff': 16, 'Waiters/barmen staff': 17}\n",
      "{'Civil marriage': 0, 'Married': 1, 'Separated': 2, 'Single / not married': 3, 'Widow': 4}\n",
      "{'F': 0, 'M': 1}\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "for x in df[non_numeric_col]:\n",
    "    df[x] = le.fit_transform(df[x])\n",
    "    print(dict(zip(le.classes_, le.transform(le.classes_))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.pop('label')\n",
    "X = df\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model\n",
    "\n",
    "### Train the SGDClassifier with default params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94       245\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.89       274\n",
      "   macro avg       0.45      0.50      0.47       274\n",
      "weighted avg       0.80      0.89      0.84       274\n",
      "\n",
      "GENDER: 55.3221\n",
      "Car_Owner: 9.6993\n",
      "Propert_Owner: -6.8254\n",
      "CHILDREN: -18.6802\n",
      "Annual_income: -57032.0078\n",
      "Type_Income: -523.4041\n",
      "EDUCATION: -54.9628\n",
      "Marital_status: 134.7128\n",
      "Housing_type: -149.4414\n",
      "Birthday_count: -6207.9247\n",
      "Employed_days: 443165.9302\n",
      "Type_Occupation: -929.3386\n",
      "Family_Members: -141.5382\n"
     ]
    }
   ],
   "source": [
    "# Create and train model\n",
    "model = SGDClassifier(random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Importance of each feature\n",
    "coefficients = model.coef_\n",
    "feature_names = X_train.columns\n",
    "for feature, importance in zip(feature_names, coefficients[0]):\n",
    "    print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'alpha': 0.001, 'learning_rate': 'optimal', 'loss': 'hinge', 'penalty': 'elasticnet', 'shuffle': True}\n",
      "Best accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create and train model\n",
    "model = SGDClassifier(random_state=42)\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "params = {\n",
    "    'loss': ['hinge', 'log_loss', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error', 'huber',\n",
    "             'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet', None],\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "    'shuffle': [True, False],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, params, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print('Best parameters: ', grid_search.best_params_)\n",
    "print('Best accuracy: {:.2f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94       245\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.89       274\n",
      "   macro avg       0.45      0.50      0.47       274\n",
      "weighted avg       0.80      0.89      0.84       274\n",
      "\n",
      "GENDER: 6.1813\n",
      "Car_Owner: 0.6041\n",
      "Propert_Owner: 0.0000\n",
      "CHILDREN: -2.0477\n",
      "Annual_income: -1508.9270\n",
      "Type_Income: -59.1983\n",
      "EDUCATION: -4.5223\n",
      "Marital_status: 17.3878\n",
      "Housing_type: -21.5410\n",
      "Birthday_count: -4074.7790\n",
      "Employed_days: 46690.6630\n",
      "Type_Occupation: -113.5839\n",
      "Family_Members: -16.2141\n"
     ]
    }
   ],
   "source": [
    "# # Evaluate the accuracy with the GridSearchCV best model\n",
    "model_best = grid_search.best_estimator_\n",
    "y_pred = model_best.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Importance of each feature\n",
    "coefficients = model_best.coef_\n",
    "feature_names = X_train.columns\n",
    "for feature, importance in zip(feature_names, coefficients[0]):\n",
    "    print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5 Use GridSearchCV to tune the parameter of each of the above models. Can you obtain better results in this step for any of the models? Discuss your observations.\n",
    "\n",
    "No. The testing accuracy given by the models trained with default parameters and GridSearchCV best parameters are almost the same in this dataset.\n",
    "\n",
    "The GridSearchCV is suggesting below parameters:\n",
    "```python\n",
    "{\n",
    "    'alpha': 0.001,\n",
    "    'learning_rate': 'optimal',\n",
    "    'loss': 'hinge',\n",
    "    'penalty': 'elasticnet',\n",
    "    'shuffle': True\n",
    "}\n",
    "```\n",
    "\n",
    "From the (SGDClassifier document)[https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html], we can see that the default parameters are:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'alpha': 0.0001,\n",
    "    'learning_rate': 'optimal',\n",
    "    'loss': 'hinge',\n",
    "    'penalty': 'l2',\n",
    "    'shuffle': True\n",
    "}\n",
    "```\n",
    "\n",
    "For SGDClassifier, `learning_rate` and `loss` are 2 important factors, since they are the same in the 2 models, it is not suprise they are providing similar accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6 Randomly (or based on certain hypothesis) remove some features and re-evaluate the models. Document your observations with respect to models performances.\n",
    "\n",
    "\n",
    "From the coefficients report, we found that `Employed_days`, `Birthday_count` and `Annual_income` are having the highest values. I am going to drop these features to see what will happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Car_Owner', 'CHILDREN', 'EDUCATION', 'Marital_status', 'Housing_type',\n",
       "       'Family_Members'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_features = ['Annual_income', 'Type_Occupation', 'Employed_days', 'Propert_Owner', 'Type_Income', 'GENDER', 'Birthday_count']\n",
    "X_train_drop = X_train.drop(drop_features, axis=1)\n",
    "X_test_drop = X_test.drop(drop_features, axis=1)\n",
    "X_train_drop.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'alpha': 0.0001, 'learning_rate': 'optimal', 'loss': 'modified_huber', 'penalty': 'l1', 'shuffle': True}\n",
      "Best accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "model = SGDClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(model, params, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_drop, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print('Best parameters: ', grid_search.best_params_)\n",
    "print('Best accuracy: {:.2f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95       245\n",
      "           1       1.00      0.10      0.19        29\n",
      "\n",
      "    accuracy                           0.91       274\n",
      "   macro avg       0.95      0.55      0.57       274\n",
      "weighted avg       0.91      0.91      0.87       274\n",
      "\n",
      "Car_Owner: 0.6935\n",
      "CHILDREN: -29.8752\n",
      "EDUCATION: -1.0647\n",
      "Marital_status: 10.9543\n",
      "Housing_type: 0.0000\n",
      "Family_Members: 28.5413\n"
     ]
    }
   ],
   "source": [
    "# # Evaluate the accuracy with the GridSearchCV best model\n",
    "model_drop_best = grid_search.best_estimator_\n",
    "y_pred = model_drop_best.predict(X_test_drop)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Importance of each feature\n",
    "coefficients = model_drop_best.coef_\n",
    "feature_names = X_train_drop.columns\n",
    "for feature, importance in zip(feature_names, coefficients[0]):\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, the test accuracy of the new model improved from 0.89 to 0.91."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-venv-4001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
